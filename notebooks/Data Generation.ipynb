{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11222,"status":"ok","timestamp":1758863064361,"user":{"displayName":"Gyu Rho","userId":"12982909790841439689"},"user_tz":-600},"id":"G3CbwbY_CtZR","outputId":"aa200d39-9866-4fe9-9d96-657002061395"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Device set to use cuda:0\n"]}],"source":["from utils.models import get_model, get_tokenizer, ground_truth_reward_model\n","from utils.data_loader import get_data\n","from utils.reward_scoring import generate_output, get_ground_truth_rewards, truncate_batch\n","from utils.data_preprocessing import response_quality_control\n","from peft import PeftModel\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4126,"status":"ok","timestamp":1758863068490,"user":{"displayName":"Gyu Rho","userId":"12982909790841439689"},"user_tz":-600},"id":"8IoHRExyCtZS","outputId":"2dfe4083-55d5-45dc-b1a7-d8e8a2df5cdb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading rows 0 to 12000 from 'stanfordnlp/imdb'...\n"]}],"source":["\n","# CONFIG\n","batch_size = 100\n","for_sft = False\n","for_dpo = True\n","prompt_length = 20\n","max_length = 196\n","# Get Model\n","wdir = '.'\n","model_name = 'google/gemma-3-270m'\n","\n","base_model = get_model(model_name).to('cuda')\n","base_model = PeftModel.from_pretrained(base_model,\n","                                      f'{wdir}/models/sft/best_model')\n","tok = get_tokenizer(model_name)\n","\n","# Get data\n","base_data = get_data('train', 0, 12000)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3484308,"status":"error","timestamp":1758866552810,"user":{"displayName":"Gyu Rho","userId":"12982909790841439689"},"user_tz":-600},"id":"b5b2gGx-CtZS","outputId":"09acf3f1-1851-49ec-c04b-04212e0f0562"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing batch starting at index 0: I rented I AM CURIOU\n","Processing batch starting at index 100: Terrible movie. Nuff\n","Processing batch starting at index 200: This is an action We\n","Processing batch starting at index 300: Unlike \"The Adventur\n","Processing batch starting at index 400: This was an incredib\n","Processing batch starting at index 500: When I ordered this \n"]},{"name":"stderr","output_type":"stream","text":["You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"]},{"name":"stdout","output_type":"stream","text":["Processing batch starting at index 600: I've been going thro\n","Processing batch starting at index 700: \"Feast of All Saints\n","Processing batch starting at index 800: I've come to realise\n","Processing batch starting at index 900: Honestly before I wa\n","Processing batch starting at index 1000: Although I have to a\n","Processing batch starting at index 1100: The only thing remar\n","Processing batch starting at index 1200: Della Myers (Kim Bas\n","Processing batch starting at index 1300: It's hard to believe\n","Processing batch starting at index 1400: I wish more movies w\n","Processing batch starting at index 1500: Start of with the go\n","Processing batch starting at index 1600: NATIONAL LAMPOON'S C\n","Processing batch starting at index 1700: This film is not dev\n","Processing batch starting at index 1800: Formula flick of guy\n","Processing batch starting at index 1900: Need a lesson in pur\n","Processing batch starting at index 2000: Darcy and her young \n","Processing batch starting at index 2100: I go to UCSB and tak\n","Processing batch starting at index 2200: Boy what a dud this \n","Processing batch starting at index 2300: I just loved watchin\n","Processing batch starting at index 2400: A film so insecure t\n","Processing batch starting at index 2500: Maiden Voyage is jus\n","Processing batch starting at index 2600: I'll say one thing f\n","Processing batch starting at index 2700: Considering the limi\n","Processing batch starting at index 2800: MINOR SPOILERS!<br /\n","Processing batch starting at index 2900: It's made in 2007 an\n","Processing batch starting at index 3000: This is a bad movie.\n","Processing batch starting at index 3100: Was this the greates\n","Processing batch starting at index 3200: Two sisters, their p\n","Processing batch starting at index 3300: This is an installme\n","Processing batch starting at index 3400: I first saw the live\n","Processing batch starting at index 3500: Ritchie's first two \n","Processing batch starting at index 3600: Not the best of acto\n","Processing batch starting at index 3700: I wasn't as \"lucky\" \n","Processing batch starting at index 3800: I am a huge fan of D\n","Processing batch starting at index 3900: I'm glad I rented th\n","Processing batch starting at index 4000: There is one really \n","Processing batch starting at index 4100: This is an amateur m\n","Processing batch starting at index 4200: I thank god I didn't\n","Processing batch starting at index 4300: I can't understand w\n","Processing batch starting at index 4400: This agonizing comed\n","Processing batch starting at index 4500: Well, what can I say\n","Processing batch starting at index 4600: As a fan of Science-\n","Processing batch starting at index 4700: I rented this movie \n","Processing batch starting at index 4800: I myself am a big fa\n","Processing batch starting at index 4900: In light of the rece\n","Processing batch starting at index 5000: I used to be an avid\n","Processing batch starting at index 5100: ...And I never thoug\n","Processing batch starting at index 5200: i rate this movie wi\n","Processing batch starting at index 5300: I can't believe that\n","Processing batch starting at index 5400: I'll bet none of you\n","Processing batch starting at index 5500: Released on DVD in t\n","Processing batch starting at index 5600: I think the biggest \n","Processing batch starting at index 5700: Consider for a momen\n","Processing batch starting at index 5800: I enjoy quality crap\n","Processing batch starting at index 5900: Sundown - featuring \n","Processing batch starting at index 6000: I live in Salt Lake \n","Processing batch starting at index 6100: I have to say as bei\n","Processing batch starting at index 6200: This really was a wa\n","Processing batch starting at index 6300: ...cause they're bot\n","Processing batch starting at index 6400: Surely no Saturday m\n","Processing batch starting at index 6500: so altogether i foun\n","Processing batch starting at index 6600: Interesting idea and\n","Processing batch starting at index 6700: One wonders why anyo\n","Processing batch starting at index 6800: The plot is rocky. T\n","Processing batch starting at index 6900: The Comeback starts \n","Processing batch starting at index 7000: Don't you just hate \n","Processing batch starting at index 7100: I am SURE there is s\n","Processing batch starting at index 7200: This star-studded Br\n","Processing batch starting at index 7300: This movie was awful\n","Processing batch starting at index 7400: when you get to the \n","Processing batch starting at index 7500: To be honest I knew \n","Processing batch starting at index 7600: I'm not going to com\n","Processing batch starting at index 7700: This is one of those\n","Processing batch starting at index 7800: I started to watch t\n","Processing batch starting at index 7900: This is a weak seque\n","Processing batch starting at index 8000: this by far one of t\n","Processing batch starting at index 8100: I actually prefer Ro\n","Processing batch starting at index 8200: What this movie fail\n","Processing batch starting at index 8300: i read the book \"7 y\n","Processing batch starting at index 8400: This piece of crap, \n","Processing batch starting at index 8500: This was a big disap\n","Processing batch starting at index 8600: This is easily one o\n","Processing batch starting at index 8700: I'm afraid this one \n","Processing batch starting at index 8800: This movie kinda let\n","Processing batch starting at index 8900: Easily the best know\n","Processing batch starting at index 9000: This movie forever l\n","Processing batch starting at index 9100: Many people like to \n","Processing batch starting at index 9200: Alright normally i a\n","Processing batch starting at index 9300: 'The Omen 4: The Awa\n","Processing batch starting at index 9400: Heavily re-edited an\n","Processing batch starting at index 9500: Someone, some day, s\n","Processing batch starting at index 9600: Another of my delves\n","Processing batch starting at index 9700: Okay, I absolutely L\n","Processing batch starting at index 9800: Not the worst movie \n","Processing batch starting at index 9900: The film-school inte\n","Processing batch starting at index 10000: Someone actually gav\n","Processing batch starting at index 10100: I saw this piece of \n","Processing batch starting at index 10200: It has been said, \"a\n","Processing batch starting at index 10300: The \"math\" aspect to\n","Processing batch starting at index 10400: This film had so muc\n","Processing batch starting at index 10500: ...but a lousy film.\n","Processing batch starting at index 10600: I've seen a lot of m\n","Processing batch starting at index 10700: You have to figure t\n","Processing batch starting at index 10800: My guess is that thi\n","Processing batch starting at index 10900: I greatly enjoyed Ma\n","Processing batch starting at index 11000: ......this film is p\n","Processing batch starting at index 11100: This is certainly th\n","Processing batch starting at index 11200: The turgid pace of t\n","Processing batch starting at index 11300: \"Nat\" (voiced by Tre\n","Processing batch starting at index 11400: I had the (mis)fortu\n","Processing batch starting at index 11500: The story line has b\n","Processing batch starting at index 11600: I decided to watch t\n","Processing batch starting at index 11700: Don't really know wh\n","Processing batch starting at index 11800: My wife and I rented\n","Processing batch starting at index 11900: I dislike this movie\n"]},{"ename":"OSError","evalue":"Cannot save file into a non-existent directory: 'data'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4075068464.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Display the first few rows of the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mdf_medium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/dpo_data_medium.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mdf_low\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/dpo_data_low.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mdf_high\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/dpo_data_high.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 )\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3965\u001b[0m         )\n\u001b[1;32m   3966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3967\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3968\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         )\n\u001b[0;32m-> 1014\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \"\"\"\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0;31m# Only for write methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mrf\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'data'"]}],"source":["first_responses = []\n","second_responses = []\n","negative_responses = []\n","first_response_scores = []\n","second_response_scores = []\n","negative_response_scores = []\n","# Loop from 0 to the end of the list, jumping by batch_size each time\n","for i in range(0, len(base_data), batch_size):\n","    # Slice the list to get the current batch\n","    batch = base_data[i : i + batch_size]\n","\n","    print(f\"Processing batch starting at index {i}: {batch[0][:20]}\")\n","    responses = generate_output(base_model, tok, batch, prompt_length, max_length,2)\n","    scores = get_ground_truth_rewards(ground_truth_reward_model, responses)\n","\n","    batch = truncate_batch(tok, batch, max_length)\n","    batch_score = get_ground_truth_rewards(ground_truth_reward_model, batch)\n","\n","    first_responses.extend(responses[0::2])\n","    second_responses.extend(responses[1::2])\n","    negative_responses.extend(batch)\n","    first_response_scores.extend(scores[0::2])\n","    second_response_scores.extend(scores[1::2])\n","    negative_response_scores.extend(batch_score)\n","\n","\n","# Create a DataFrame from the lists\n","df = pd.DataFrame({\n","    'first_response': first_responses,\n","    'second_response': second_responses,\n","    'negative_response': negative_responses,\n","    'first_response_score': first_response_scores,\n","    'second_response_score': second_response_scores,\n","    'negative_response_score': negative_response_scores\n","})\n","\n","# Example usage:\n","df_medium = response_quality_control(df, 6000)\n","df_low = response_quality_control(df, 12000)\n","df_high = df[['first_response', 'second_response', 'first_response_score', 'second_response_score']]\n","\n","\n","# Generate one permutation of indices from the original df\n","shuffled_index = np.random.permutation(df.index)\n","\n","# Display the first few rows of the DataFrame\n","df_medium.reindex(shuffled_index).reset_index(drop=True).to_csv(f'{wdir}/data/dpo_data_medium.csv', index=False)\n","df_low.reindex(shuffled_index).reset_index(drop=True).to_csv(f'{wdir}/data/dpo_data_low.csv', index=False)\n","df_high.reindex(shuffled_index).reset_index(drop=True).to_csv(f'{wdir}/data/dpo_data_high.csv', index=False)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2245,"status":"ok","timestamp":1758866868964,"user":{"displayName":"Gyu Rho","userId":"12982909790841439689"},"user_tz":-600},"id":"7XAnXTs6ofLN"},"outputs":[],"source":["# Display the first few rows of the DataFrame\n","df_medium.reindex(shuffled_index).reset_index(drop=True).to_csv(f'{wdir}/data/dpo_data_medium.csv', index=False)\n","df_low.reindex(shuffled_index).reset_index(drop=True).to_csv(f'{wdir}/data/dpo_data_low.csv', index=False)\n","df_high.reindex(shuffled_index).reset_index(drop=True).to_csv(f'{wdir}/data/dpo_data_high.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tSNw3XY5ogG1"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
