{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11801,"status":"ok","timestamp":1758963185610,"user":{"displayName":"Gyu Rho","userId":"12982909790841439689"},"user_tz":-600},"id":"hU-y_Cn6Bb59","outputId":"098e3d70-5a90-44d2-fd40-d8787f98296a"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Device set to use cuda:0\n"]}],"source":["from utils.models import get_model, get_tokenizer, ground_truth_reward_model, CustomModel\n","from utils.evaluation import evaluate_ground_truth_rewards\n","from utils.data_preprocessing import CustomDataset, transform_df_for_dpo, precompute_reference_log_probs_batched\n","from utils.loss_functions import MADPOLoss\n","from utils.utils import get_log_probs, describe_rewards, get_reward\n","from utils.preference_generation import determine_preference\n","\n","import torch\n","from torch.utils.data import DataLoader\n","from transformers import get_cosine_schedule_with_warmup\n","from peft import LoraConfig, PeftModel\n","\n","from tqdm import tqdm\n","import pandas as pd\n","import numpy as np\n","import gc, os\n","import glob"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Q5Sgh2VBb59"},"outputs":[],"source":["# --- Hyper‑parameters ---\n","wdir = '.'\n","MAX_LEN = 1024                         # truncate long GSM8K chains of thought\n","QUALITY = 'high'\n","OUTPUT_DIR = f\"{wdir}/models/MADPO_{QUALITY}\"              # where to write LoRA adapter & tokenizer\n","BATCH_SIZE = 16\n","GRAD_ACCUM = 2                         # effective batch 32\n","LR = 1e-5\n","EPOCHS = 2\n","# Define total training steps\n","dataset_size = 10000\n","effective_batch_size = BATCH_SIZE * GRAD_ACCUM  # per_device_batch_size * num_gpus * grad_accum\n","TOTAL_STEP = (dataset_size // effective_batch_size + 1) * EPOCHS  # 684 steps\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","prompt_length = 20\n","max_length = 196\n","\n","rng = np.random.default_rng(42)\n","scale = 1.0\n","\n","# Model Param\n","beta = 0.1\n","c_max = 2\n","c_min = 1/c_max\n","lmbda = 1\n","tau = np.log(0.999/0.001)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6756,"status":"ok","timestamp":1758963192406,"user":{"displayName":"Gyu Rho","userId":"12982909790841439689"},"user_tz":-600},"id":"Rpz0l6UIBb5-","outputId":"6ca6ffca-a829-47e0-ccf5-ed4a15b02b70"},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 1,474,560 || all params: 271,047,296 || trainable%: 0.5440\n"]}],"source":["\n","# Get Model\n","model_name = 'google/gemma-3-270m'\n","\n","policy_model = get_model(model_name).to(device)\n","policy_model = PeftModel.from_pretrained(policy_model,\n","                                         f'{wdir}/models/sft/best_model',\n","                                         adapter_name = 'sft')\n","ref_model = get_model(model_name).to(device)\n","ref_model = PeftModel.from_pretrained(ref_model,\n","                                     f'{wdir}/models/sft/best_model')\n","\n","reward_model = CustomModel(model_name, 1,\n","                           f'{wdir}/models/Reward_{QUALITY}/best_model')\n","reward_model.to(device)\n","\n","tok = get_tokenizer(model_name)\n","\n","# LoRA Config (CHANGED for Gemma)\n","lora_config = LoraConfig(\n","    r=16,\n","    lora_alpha=32,\n","    # CHANGED: Target modules for Gemma\n","    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    # CHANGED: Task type for Causal LM\n","    task_type=\"CAUSAL_LM\"\n",")\n","\n","policy_model.add_adapter(\"dpo\", lora_config)  # Adds new empty trainable adapter\n","# Set active adapters for composition (SFT + DPO for policy)\n","policy_model.base_model.set_adapter([\"sft\", \"dpo\"])\n","\n","for name, param in policy_model.named_parameters():\n","    if 'dpo' not in name:\n","        param.requires_grad = False\n","\n","policy_model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":197852,"status":"ok","timestamp":1758963390256,"user":{"displayName":"Gyu Rho","userId":"12982909790841439689"},"user_tz":-600},"id":"i149qmi9Bb5-","outputId":"d336122f-9bbd-49ac-9e67-7ed5189d9de2"},"outputs":[{"name":"stdout","output_type":"stream","text":["['/content/drive/Othercomputers/My MacBook Pro/Oracle DPO/data/dpo_data_low.csv']\n","pref\n","1 > 2    9791\n","2 > 1    2209\n","Name: count, dtype: int64\n","Pre-computing reference log probabilities in batches...\n"]},{"name":"stderr","output_type":"stream","text":["Batches: 100%|██████████| 313/313 [02:44<00:00,  1.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Pre-computing reference log probabilities in batches...\n"]},{"name":"stderr","output_type":"stream","text":["Batches: 100%|██████████| 63/63 [00:32<00:00,  1.92it/s]\n"]}],"source":["# Path to the folder containing the CSV files\n","path = f'{wdir}/data/'\n","\n","# Get a list of all CSV files in the folder\n","all_files = glob.glob(path + f\"dpo_data_{QUALITY}.csv\")\n","\n","print(all_files)\n","# Expected output: ['data/sales_jan.csv', 'data/sales_feb.csv', 'data/sales_mar.csv']\n","# Read each CSV file into a DataFrame and store them in a list\n","list_of_dfs = [pd.read_csv(file) for file in all_files]\n","\n","# Concatenate all DataFrames in the list by row\n","df = pd.concat(list_of_dfs, ignore_index=True)\n","\n","df['pref'] = df.apply(determine_preference,\n","                      axis=1,\n","                      args=(scale, rng)  # scale=2.0, rng=custom generator)\n",")\n","print(df.pref.value_counts())\n","\n","# # --- DATA PROCESS ---\n","df = transform_df_for_dpo(df)\n","train_ref_y1, train_ref_y2 = precompute_reference_log_probs_batched(ref_model, tok, df[:dataset_size], effective_batch_size, device, prompt_length, max_length)\n","eval_ref_y1, eval_ref_y2 = precompute_reference_log_probs_batched(ref_model, tok, df[dataset_size:], effective_batch_size, device, prompt_length, max_length)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V2k5t69UBb5_"},"outputs":[],"source":["# --- Create DataLoaders ---\n","train_dataset = CustomDataset(df[:dataset_size], train_ref_y1, train_ref_y2)\n","eval_dataset = CustomDataset(df[dataset_size:], eval_ref_y1, eval_ref_y2)\n","train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=lambda batch: batch)\n","eval_dataloader = DataLoader(eval_dataset, batch_size=BATCH_SIZE, collate_fn=lambda batch: batch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wPdfQdZcBb5_"},"outputs":[],"source":["# --- Training Components ---\n","loss_fn = MADPOLoss(beta, c_max, c_min, lmbda, tau) # beta, clip, ref_mean_scale\n","# The optimizer will only see the trainable PEFT parameters\n","optimizer = torch.optim.AdamW(\n","    policy_model.parameters(),\n","    lr=LR,\n","    betas=(0.9, 0.95),\n","    eps=1e-8,\n","    weight_decay=0.01\n",")\n","\n","\n","# Cosine scheduler\n","scheduler = get_cosine_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps = int(0.03 * TOTAL_STEP),\n","    num_training_steps = TOTAL_STEP\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1573091,"status":"ok","timestamp":1758964963371,"user":{"displayName":"Gyu Rho","userId":"12982909790841439689"},"user_tz":-600},"id":"Rwj6bIk8Bb6A","outputId":"20d3e88f-e4da-4ed7-a938-ba75754461b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","--- Starting Training ---\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1: 100%|██████████| 625/625 [13:09<00:00,  1.26s/it]\n","Epoch 2: 100%|██████████| 625/625 [13:03<00:00,  1.25s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","--- Training Finished ---\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# --- Early Stopping and Model Saving Variables ---\n","global_step = 0\n","print(\"\\n--- Starting Training ---\")\n","for epoch in range(EPOCHS):\n","\n","    # Note: optimizer.zero_grad() is now inside the accumulation block\n","\n","    # Use enumerate to get the batch index 'i'\n","    for i, batch in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\")):\n","        policy_model.train()\n","        # --- Forward Pass ---\n","        log_probs_y1_policy = get_log_probs(policy_model, tok, batch, 'first_responses', device, prompt_length, max_length)\n","        log_probs_y2_policy = get_log_probs(policy_model, tok, batch, 'second_responses', device, prompt_length, max_length)\n","\n","        # Get rewards\n","        with torch.no_grad():\n","          r1 = get_reward(reward_model, tok, batch, 'first_responses', device, max_length)\n","          r2 = get_reward(reward_model, tok, batch, 'second_responses', device, max_length)\n","\n","        # Stack the tensor items\n","        choices = torch.stack([item['choices'] for item in batch])\n","        ref_log_probs_y1 = torch.stack([item['ref_log_probs_y1'] for item in batch])\n","        ref_log_probs_y2 = torch.stack([item['ref_log_probs_y2'] for item in batch])\n","\n","        loss = loss_fn(\n","            log_probs_y1_policy,\n","            log_probs_y2_policy,\n","            ref_log_probs_y1.to(device),\n","            ref_log_probs_y2.to(device),\n","            r1.detach(),\n","            r2.detach(),\n","            choices.to(device)\n","        )\n","\n","        # --- Scale the Loss and Backpropagate ---\n","        loss = loss / GRAD_ACCUM\n","        loss.backward()\n","\n","        # --- Optimizer Step ---\n","        if (global_step + 1) % GRAD_ACCUM == 0:\n","            torch.nn.utils.clip_grad_norm_(policy_model.parameters(), 1.0)\n","            optimizer.step()\n","            scheduler.step()\n","            optimizer.zero_grad()\n","\n","        global_step += 1 # Increment global_step only when weights are updated\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","\n","print(\"\\n--- Training Finished ---\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1361526,"status":"ok","timestamp":1758966324900,"user":{"displayName":"Gyu Rho","userId":"12982909790841439689"},"user_tz":-600},"id":"nfyPvdcGBb6A","outputId":"7755bc4c-0187-4dbc-b52f-704befb8ad37"},"outputs":[{"name":"stderr","output_type":"stream","text":["You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"]},{"name":"stdout","output_type":"stream","text":["Mean: 1.8103\n","Standard Deviation: 1.3879\n","95% Confidence Interval: (1.7494, 1.8711)\n"]}],"source":["policy_model.eval()\n","rewards = evaluate_ground_truth_rewards(policy_model, ground_truth_reward_model, tok, eval_dataloader, prompt_length, max_length)\n","describe_rewards(rewards)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
